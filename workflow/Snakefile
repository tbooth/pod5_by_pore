# vim: ft=python
"""Snakefile to re-sort POD files by channel.
   Useful for duplex calling.
"""
from collections import defaultdict
import json

INPUT_DIR  = config.get('input', "input")

# Utility functions
from common_functions import n_sorted, get_common_prefix

def list_pod5_channels(wc=None):
    """List all the .pod5.channels files (ie. one per pod5)
    """
    all_pod5 = glob_wildcards(INPUT_DIR + "/{p5}.pod5")

    assert all_pod5.p5, f"No .pod5 files seen in {INPUT_DIR}/"

    return [ f"results/tmp/{p5}.pod5.channels" for p5 in all_pod5.p5 ]

def load_channels_in_use():
    """Loads channels_in_use.json, if it's available.
    """
    with open(checkpoints.get_channels_in_use.get().output[0]) as jfh:
        return json.load(jfh)

rule main:
    input: "results/tmp/all_channels_done.touch"

localrules: get_channels_in_use, output_for_all_channels

wildcard_constraints:
    channel = r"\d+",

rule get_channels_in_pod:
    output: "results/tmp/{foo}.pod5.channels"
    input:  INPUT_DIR + "/{foo}.pod5"
    conda:  "envs/pod5.yaml"
    shell:
        "pod5 view -H {input} -i read_id,channel > {output}"

checkpoint get_channels_in_use:
    output: "results/tmp/channels_in_use.json"
    input:  list_pod5_channels
    run:
        # "cut -d, -f 1 {input} | sort -u > {output}"
        # Save channel -> pod5_files dict as json
        res = defaultdict(set)
        for f in input:
            f_base = re.search(r"/(\w+\.pod5)\.channels$", f).group(1)
            with open(f) as fh:
                for read_id, channel in (l.split() for l in fh):
                    res[channel].add(f_base)

        # Sets to lists
        with open(str(output), "x") as ofh:
            json.dump( {k: n_sorted(v) for k, v in res.items()},
                       fp = ofh,
                       sort_keys = True,
                       indent = 4 )

def i_pod5_for_channel(wc):
    """See which pod5 files have reads on a given channel, to save us scanning
       every file every time.
    """
    channel = wc.channel
    ciu = load_channels_in_use()

    return dict( pod5 = [ f"{INPUT_DIR}/{f}" for f in ciu[channel] ],
                 chan = [ f"results/tmp/{f}.channels" for f in ciu[channel] ] )

# FIXME - this could blow the command line limit if there are too many pod5 files,
# so an alternative could be to make a load of symlinks (in tmpfs) then use the
# recursive mode. Icky.
rule pod5_for_channel:
    output:
        pod5 =   "results/{pref}channel_{channel}.pod5",
        idlist = "results/tmp/{pref}channel_{channel}.idlist"
    input:
        unpack(i_pod5_for_channel)
    params:
        awk_filter = "($2=={channel}){{print$1}}"
    shell:
       r"""awk {params.awk_filter:q} {input.chan} > {output.idlist}
           pod5 filter -o {output.pod5} -i {output.idlist} {input.pod5}
        """

def i_output_for_all_channels(wc=None):
    """Reads the list of all the channels for which there are records in any POD5.
       Returns a list of POD5 files to make in ./results
    """
    ciu = load_channels_in_use()

    # Keep the common prefix from the original POD5 filenames
    common_prefix = get_common_prefix( list_pod5_channels(),
                                       base_only= True,
                                       extn = r"_\d+\.pod5\.channels")
    pref = f"{common_prefix}_" if common_prefix else ""

    return [ f"results/{pref}channel_{c}.pod5" for c in ciu ]

rule output_for_all_channels:
    output: touch("results/tmp/all_channels_done.touch")
    input:  i_output_for_all_channels
